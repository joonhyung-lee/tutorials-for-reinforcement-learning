{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKDpRBZkvNxA","outputId":"5aec7673-1a0f-4311-a071-ed70b04c872e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error delta: 0.25\n","Error delta: 0.09374999999999994\n","Error delta: 0.046874999999999986\n","Error delta: 0.028320312499999986\n","Error delta: 0.016250610351562472\n","Error delta: 0.009230613708496094\n","Error delta: 0.005255997180938721\n","Error delta: 0.003013335168361664\n","Error delta: 0.001840144395828247\n","Error delta: 0.0015904679894447327\n","Error delta: 0.0013761396985501042\n","Error delta: 0.0011462080728961137\n","Error delta: 0.0009309625911555486\n","Error delta: 0.0007432938909914793\n","Error delta: 0.0005864328780234036\n","Error delta: 0.0004588047738234291\n","Error delta: 0.000356808107080258\n","Error delta: 0.00027629247729870146\n","Error delta: 0.00021327900731391708\n","Error delta: 0.0001642637287276455\n","Error delta: 0.00012630373753949424\n","Error delta: 9.699843740286311e-05\n","Error delta: 7.442652697140124e-05\n","Error delta: 5.7069988440556704e-05\n","Error delta: 4.3740108631683955e-05\n","Error delta: 3.351189367291167e-05\n","Error delta: 2.566879565789673e-05\n","Error delta: 1.9657536659412403e-05\n","Error delta: 1.5051909316351683e-05\n","Error delta: 1.1524153836981951e-05\n","Error delta: 8.82253276934808e-06\n","Value Function:\n","[0.013911   0.01161424 0.02094062 0.01046758 0.01623478 0.\n"," 0.04074774 0.         0.03479961 0.08816698 0.14205099 0.\n"," 0.         0.17581855 0.4392897  0.        ]\n","\n"]}],"source":["import gym\n","import numpy as np\n","\n","env = gym.make('FrozenLake-v1')\n","\n","def policy_eval(policy, env, discount_factor=1.0, theta=0.00001):\n","    # Start with a random (all 0) value function\n","    V = np.zeros(env.nS)\n","    while True:\n","        delta = 0\n","        # For each state, perform a \"full backup\"\n","        for s in range(env.nS):\n","            v = 0\n","            # Look at the possible next actions\n","            for a, action_prob in enumerate(policy[s]):\n","                # For each action, look at the possible next states...\n","                for  transition_prob, next_state, reward, done in env.P[s][a]:\n","                    # Calculate the expected value. Ref: Sutton book eq. 4.6.\n","                    v = v + action_prob * transition_prob * (reward + discount_factor * V[next_state])\n","            # How much our value function changed (across any states)\n","            delta = max(delta, np.abs(v - V[s]))\n","            V[s] = v\n","        print('Error delta: {0}'.format(delta))\n","        # Stop evaluating once our value function change is below a threshold\n","        if delta < theta:\n","            break\n","    return np.array(V)\n","\n","random_policy = np.ones([env.nS, env.nA]) / env.nA\n","v = policy_eval(random_policy, env)\n","\n","print(\"Value Function:\")\n","print(v)\n","print(\"\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jhjuPJoPvNxC"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"PE.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}
