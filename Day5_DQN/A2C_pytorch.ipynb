{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ur2hJpmA7XD2","executionInfo":{"status":"ok","timestamp":1646767213996,"user_tz":-540,"elapsed":194730,"user":{"displayName":"Okyong Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgXt3H1vBv3hDstzKZEIDl0RZQP9ouHdNHms_-n8g=s64","userId":"02726249487150490039"}},"outputId":"83230dea-7e6c-4d64-8cf7-a059be490aa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Step # :500, avg score : 23.2\n","Step # :1000, avg score : 46.6\n","Step # :1500, avg score : 44.5\n","Step # :2000, avg score : 42.2\n","Step # :2500, avg score : 69.0\n","Step # :3000, avg score : 50.0\n","Step # :3500, avg score : 72.9\n","Step # :4000, avg score : 106.3\n","Step # :4500, avg score : 90.1\n","Step # :5000, avg score : 126.5\n","Step # :5500, avg score : 96.1\n","Step # :6000, avg score : 119.8\n","Step # :6500, avg score : 111.5\n","Step # :7000, avg score : 139.0\n","Step # :7500, avg score : 181.4\n","Step # :8000, avg score : 172.4\n","Step # :8500, avg score : 155.0\n","Step # :9000, avg score : 143.8\n","Step # :9500, avg score : 197.5\n","Step # :10000, avg score : 268.7\n","Step # :10500, avg score : 203.2\n","Step # :11000, avg score : 209.2\n","Step # :11500, avg score : 229.6\n","Step # :12000, avg score : 227.5\n","Step # :12500, avg score : 235.9\n","Step # :13000, avg score : 227.3\n","Step # :13500, avg score : 292.4\n","Step # :14000, avg score : 280.2\n","Step # :14500, avg score : 307.3\n","Step # :15000, avg score : 286.3\n","Step # :15500, avg score : 227.5\n","Step # :16000, avg score : 310.1\n","Step # :16500, avg score : 325.4\n","Step # :17000, avg score : 357.2\n","Step # :17500, avg score : 370.7\n","Step # :18000, avg score : 305.2\n","Step # :18500, avg score : 300.2\n","Step # :19000, avg score : 273.1\n","Step # :19500, avg score : 236.3\n","Step # :20000, avg score : 263.2\n","Step # :20500, avg score : 219.3\n","Step # :21000, avg score : 249.8\n","Step # :21500, avg score : 279.7\n","Step # :22000, avg score : 380.9\n","Step # :22500, avg score : 325.9\n","Step # :23000, avg score : 329.0\n","Step # :23500, avg score : 455.6\n","Step # :24000, avg score : 392.1\n","Step # :24500, avg score : 428.1\n","Step # :25000, avg score : 287.4\n","Step # :25500, avg score : 405.1\n","Step # :26000, avg score : 410.0\n","Step # :26500, avg score : 467.7\n","Step # :27000, avg score : 475.9\n","Step # :27500, avg score : 430.9\n","Step # :28000, avg score : 414.7\n","Step # :28500, avg score : 490.7\n","Step # :29000, avg score : 439.1\n","Step # :29500, avg score : 447.3\n","Step # :30000, avg score : 450.1\n","Step # :30500, avg score : 404.6\n","Step # :31000, avg score : 423.2\n","Step # :31500, avg score : 439.5\n","Step # :32000, avg score : 497.8\n","Step # :32500, avg score : 438.6\n","Step # :33000, avg score : 461.0\n","Step # :33500, avg score : 446.9\n","Step # :34000, avg score : 460.2\n","Step # :34500, avg score : 468.8\n","Step # :35000, avg score : 467.8\n","Step # :35500, avg score : 487.3\n","Step # :36000, avg score : 480.7\n","Step # :36500, avg score : 500.0\n","Step # :37000, avg score : 458.0\n","Step # :37500, avg score : 475.5\n","Step # :38000, avg score : 485.0\n","Step # :38500, avg score : 449.3\n","Step # :39000, avg score : 448.8\n","Step # :39500, avg score : 500.0\n","Step # :40000, avg score : 500.0\n","Step # :40500, avg score : 500.0\n","Step # :41000, avg score : 496.8\n","Step # :41500, avg score : 500.0\n","Step # :42000, avg score : 442.2\n","Step # :42500, avg score : 338.7\n","Step # :43000, avg score : 256.1\n","Step # :43500, avg score : 326.1\n","Step # :44000, avg score : 500.0\n","Step # :44500, avg score : 494.7\n","Step # :45000, avg score : 477.1\n","Step # :45500, avg score : 390.3\n","Step # :46000, avg score : 300.5\n","Step # :46500, avg score : 251.4\n","Step # :47000, avg score : 294.6\n","Step # :47500, avg score : 351.8\n","Step # :48000, avg score : 385.3\n","Step # :48500, avg score : 323.6\n","Step # :49000, avg score : 395.1\n","Step # :49500, avg score : 420.4\n","Step # :50000, avg score : 410.0\n","Step # :50500, avg score : 446.6\n","Step # :51000, avg score : 410.6\n","Step # :51500, avg score : 456.6\n","Step # :52000, avg score : 468.9\n","Step # :52500, avg score : 469.9\n","Step # :53000, avg score : 403.0\n","Step # :53500, avg score : 438.2\n","Step # :54000, avg score : 493.6\n","Step # :54500, avg score : 468.6\n","Step # :55000, avg score : 498.6\n","Step # :55500, avg score : 500.0\n","Step # :56000, avg score : 500.0\n","Step # :56500, avg score : 500.0\n","Step # :57000, avg score : 500.0\n","Step # :57500, avg score : 500.0\n","Step # :58000, avg score : 500.0\n","Step # :58500, avg score : 500.0\n","Step # :59000, avg score : 500.0\n","Step # :59500, avg score : 499.4\n","Step # :60000, avg score : 500.0\n"]}],"source":["import gym\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.distributions import Categorical\n","import torch.multiprocessing as mp\n","import time\n","import numpy as np\n","\n","# Hyperparameters\n","n_train_processes = 3\n","learning_rate = 0.0002\n","update_interval = 5\n","gamma = 0.98\n","max_train_steps = 60000\n","PRINT_INTERVAL = update_interval * 100\n","\n","class ActorCritic(nn.Module):\n","    def __init__(self):\n","        super(ActorCritic, self).__init__()\n","        self.fc1 = nn.Linear(4, 256)\n","        self.fc_pi = nn.Linear(256, 2)\n","        self.fc_v = nn.Linear(256, 1)\n","\n","    def pi(self, x, softmax_dim=1):\n","        x = F.relu(self.fc1(x))\n","        x = self.fc_pi(x)\n","        prob = F.softmax(x, dim=softmax_dim)\n","        return prob\n","\n","    def v(self, x):\n","        x = F.relu(self.fc1(x))\n","        v = self.fc_v(x)\n","        return v\n","\n","def worker(worker_id, master_end, worker_end):\n","    master_end.close()  # Forbid worker to use the master end for messaging\n","    env = gym.make('CartPole-v1')\n","    env.seed(worker_id)\n","\n","    while True:\n","        cmd, data = worker_end.recv()\n","        if cmd == 'step':\n","            ob, reward, done, info = env.step(data)\n","            if done:\n","                ob = env.reset()\n","            worker_end.send((ob, reward, done, info))\n","        elif cmd == 'reset':\n","            ob = env.reset()\n","            worker_end.send(ob)\n","        elif cmd == 'reset_task':\n","            ob = env.reset_task()\n","            worker_end.send(ob)\n","        elif cmd == 'close':\n","            worker_end.close()\n","            break\n","        elif cmd == 'get_spaces':\n","            worker_end.send((env.observation_space, env.action_space))\n","        else:\n","            raise NotImplementedError\n","\n","class ParallelEnv:\n","    def __init__(self, n_train_processes):\n","        self.nenvs = n_train_processes\n","        self.waiting = False\n","        self.closed = False\n","        self.workers = list()\n","\n","        master_ends, worker_ends = zip(*[mp.Pipe() for _ in range(self.nenvs)])\n","        self.master_ends, self.worker_ends = master_ends, worker_ends\n","\n","        for worker_id, (master_end, worker_end) in enumerate(zip(master_ends, worker_ends)):\n","            p = mp.Process(target=worker,\n","                           args=(worker_id, master_end, worker_end))\n","            p.daemon = True\n","            p.start()\n","            self.workers.append(p)\n","\n","        # Forbid master to use the worker end for messaging\n","        for worker_end in worker_ends:\n","            worker_end.close()\n","\n","    def step_async(self, actions):\n","        for master_end, action in zip(self.master_ends, actions):\n","            master_end.send(('step', action))\n","        self.waiting = True\n","\n","    def step_wait(self):\n","        results = [master_end.recv() for master_end in self.master_ends]\n","        self.waiting = False\n","        obs, rews, dones, infos = zip(*results)\n","        return np.stack(obs), np.stack(rews), np.stack(dones), infos\n","\n","    def reset(self):\n","        for master_end in self.master_ends:\n","            master_end.send(('reset', None))\n","        return np.stack([master_end.recv() for master_end in self.master_ends])\n","\n","    def step(self, actions):\n","        self.step_async(actions)\n","        return self.step_wait()\n","\n","    def close(self):  # For clean up resources\n","        if self.closed:\n","            return\n","        if self.waiting:\n","            [master_end.recv() for master_end in self.master_ends]\n","        for master_end in self.master_ends:\n","            master_end.send(('close', None))\n","        for worker in self.workers:\n","            worker.join()\n","            self.closed = True\n","\n","def test(step_idx, model):\n","    env = gym.make('CartPole-v1')\n","    score = 0.0\n","    done = False\n","    num_test = 10\n","\n","    for _ in range(num_test):\n","        s = env.reset()\n","        while not done:\n","            prob = model.pi(torch.from_numpy(s).float(), softmax_dim=0)\n","            a = Categorical(prob).sample().numpy()\n","            s_prime, r, done, info = env.step(a)\n","            s = s_prime\n","            score += r\n","        done = False\n","    print(f\"Step # :{step_idx}, avg score : {score/num_test:.1f}\")\n","\n","    env.close()\n","\n","def compute_target(v_final, r_lst, mask_lst):\n","    G = v_final.reshape(-1)\n","    td_target = list()\n","\n","    for r, mask in zip(r_lst[::-1], mask_lst[::-1]):\n","        G = r + gamma * G * mask\n","        td_target.append(G)\n","\n","    return torch.tensor(td_target[::-1]).float()\n","\n","if __name__ == '__main__':\n","    envs = ParallelEnv(n_train_processes)\n","\n","    model = ActorCritic()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    step_idx = 0\n","    s = envs.reset()\n","    while step_idx < max_train_steps:\n","        s_lst, a_lst, r_lst, mask_lst = list(), list(), list(), list()\n","        for _ in range(update_interval):\n","            prob = model.pi(torch.from_numpy(s).float())\n","            a = Categorical(prob).sample().numpy()\n","            s_prime, r, done, info = envs.step(a)\n","\n","            s_lst.append(s)\n","            a_lst.append(a)\n","            r_lst.append(r/100.0)\n","            mask_lst.append(1 - done)\n","\n","            s = s_prime\n","            step_idx += 1\n","\n","        s_final = torch.from_numpy(s_prime).float()\n","        v_final = model.v(s_final).detach().clone().numpy()\n","        td_target = compute_target(v_final, r_lst, mask_lst)\n","\n","        td_target_vec = td_target.reshape(-1)\n","        s_vec = torch.tensor(s_lst).float().reshape(-1, 4)  # 4 == Dimension of state\n","        a_vec = torch.tensor(a_lst).reshape(-1).unsqueeze(1)\n","        advantage = td_target_vec - model.v(s_vec).reshape(-1)\n","\n","        pi = model.pi(s_vec, softmax_dim=1)\n","        pi_a = pi.gather(1, a_vec).reshape(-1)\n","        loss = -(torch.log(pi_a) * advantage.detach()).mean() +\\\n","            F.smooth_l1_loss(model.v(s_vec).reshape(-1), td_target_vec)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if step_idx % PRINT_INTERVAL == 0:\n","            test(step_idx, model)\n","\n","    envs.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TpK52Q-l7XD7"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"A2C_pytorch.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}