{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hopel\\anaconda3\\envs\\openai\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1143..1442 -> 299-tiles track\n",
      "# of episode :0, avg score : -0.1\n",
      "Track generation: 1087..1369 -> 282-tiles track\n",
      "# of episode :1, avg score : -0.1\n",
      "Track generation: 964..1212 -> 248-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1176..1474 -> 298-tiles track\n",
      "# of episode :2, avg score : -0.1\n",
      "Track generation: 1283..1608 -> 325-tiles track\n",
      "# of episode :3, avg score : -0.1\n",
      "Track generation: 1217..1526 -> 309-tiles track\n",
      "# of episode :4, avg score : -0.1\n",
      "Track generation: 1096..1374 -> 278-tiles track\n",
      "# of episode :5, avg score : -0.1\n",
      "Track generation: 1198..1501 -> 303-tiles track\n",
      "# of episode :6, avg score : -0.1\n",
      "Track generation: 1159..1453 -> 294-tiles track\n",
      "# of episode :7, avg score : -0.1\n",
      "Track generation: 957..1205 -> 248-tiles track\n",
      "# of episode :8, avg score : -0.1\n",
      "Track generation: 1181..1480 -> 299-tiles track\n",
      "# of episode :9, avg score : -0.1\n",
      "Track generation: 979..1234 -> 255-tiles track\n",
      "# of episode :10, avg score : 1.0\n",
      "Track generation: 1320..1654 -> 334-tiles track\n",
      "# of episode :11, avg score : -0.1\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "# of episode :12, avg score : -0.1\n",
      "Track generation: 1067..1338 -> 271-tiles track\n",
      "# of episode :13, avg score : -0.1\n",
      "Track generation: 1207..1513 -> 306-tiles track\n",
      "# of episode :14, avg score : -0.1\n",
      "Track generation: 1106..1396 -> 290-tiles track\n",
      "# of episode :15, avg score : 1.0\n",
      "Track generation: 1296..1628 -> 332-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1047..1319 -> 272-tiles track\n",
      "# of episode :16, avg score : 1.0\n",
      "Track generation: 1245..1560 -> 315-tiles track\n",
      "# of episode :17, avg score : -0.1\n",
      "Track generation: 1232..1544 -> 312-tiles track\n",
      "# of episode :18, avg score : -0.1\n",
      "Track generation: 1120..1408 -> 288-tiles track\n",
      "# of episode :19, avg score : 1.0\n",
      "Track generation: 1225..1536 -> 311-tiles track\n",
      "# of episode :20, avg score : -0.1\n",
      "Track generation: 1077..1357 -> 280-tiles track\n",
      "# of episode :21, avg score : 1.0\n",
      "Track generation: 1322..1664 -> 342-tiles track\n",
      "# of episode :22, avg score : -0.1\n",
      "Track generation: 1035..1297 -> 262-tiles track\n",
      "# of episode :23, avg score : -0.1\n",
      "Track generation: 1297..1626 -> 329-tiles track\n",
      "# of episode :24, avg score : -0.1\n",
      "Track generation: 1294..1621 -> 327-tiles track\n",
      "# of episode :25, avg score : -0.1\n",
      "Track generation: 1055..1331 -> 276-tiles track\n",
      "# of episode :26, avg score : 1.0\n",
      "Track generation: 1202..1507 -> 305-tiles track\n",
      "# of episode :27, avg score : -0.1\n",
      "Track generation: 863..1087 -> 224-tiles track\n",
      "# of episode :28, avg score : 1.0\n",
      "Track generation: 1227..1538 -> 311-tiles track\n",
      "# of episode :29, avg score : -0.1\n",
      "Track generation: 1317..1652 -> 335-tiles track\n",
      "# of episode :30, avg score : -0.1\n",
      "Track generation: 1115..1402 -> 287-tiles track\n",
      "# of episode :31, avg score : 1.0\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "# of episode :32, avg score : -0.1\n",
      "Track generation: 1056..1324 -> 268-tiles track\n",
      "# of episode :33, avg score : -0.1\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "# of episode :34, avg score : -0.1\n",
      "Track generation: 1260..1579 -> 319-tiles track\n",
      "# of episode :35, avg score : -0.1\n",
      "Track generation: 1100..1379 -> 279-tiles track\n",
      "# of episode :36, avg score : -0.1\n",
      "Track generation: 1185..1485 -> 300-tiles track\n",
      "# of episode :37, avg score : -0.1\n",
      "Track generation: 1034..1296 -> 262-tiles track\n",
      "# of episode :38, avg score : -0.1\n",
      "Track generation: 1076..1352 -> 276-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1132..1419 -> 287-tiles track\n",
      "# of episode :39, avg score : -0.1\n",
      "Track generation: 1292..1619 -> 327-tiles track\n",
      "# of episode :40, avg score : -0.1\n",
      "Track generation: 1275..1598 -> 323-tiles track\n",
      "# of episode :41, avg score : -0.1\n",
      "Track generation: 1056..1324 -> 268-tiles track\n",
      "# of episode :42, avg score : -0.1\n",
      "Track generation: 1092..1377 -> 285-tiles track\n",
      "# of episode :43, avg score : 1.0\n",
      "Track generation: 1127..1413 -> 286-tiles track\n",
      "# of episode :44, avg score : -0.1\n",
      "Track generation: 1104..1384 -> 280-tiles track\n",
      "# of episode :45, avg score : -0.1\n",
      "Track generation: 1131..1430 -> 299-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1195..1498 -> 303-tiles track\n",
      "# of episode :46, avg score : -0.1\n",
      "Track generation: 1155..1448 -> 293-tiles track\n",
      "# of episode :47, avg score : -0.1\n",
      "Track generation: 1317..1650 -> 333-tiles track\n",
      "# of episode :48, avg score : -0.1\n",
      "Track generation: 1180..1479 -> 299-tiles track\n",
      "# of episode :49, avg score : -0.1\n",
      "Track generation: 1170..1467 -> 297-tiles track\n",
      "# of episode :50, avg score : -0.1\n",
      "Track generation: 1022..1282 -> 260-tiles track\n",
      "# of episode :51, avg score : -0.1\n",
      "Track generation: 1230..1542 -> 312-tiles track\n",
      "# of episode :52, avg score : -0.1\n",
      "Track generation: 1018..1278 -> 260-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1126..1412 -> 286-tiles track\n",
      "# of episode :53, avg score : -0.1\n",
      "Track generation: 1251..1568 -> 317-tiles track\n",
      "# of episode :54, avg score : -0.1\n",
      "Track generation: 1202..1507 -> 305-tiles track\n",
      "# of episode :55, avg score : -0.1\n",
      "Track generation: 1265..1592 -> 327-tiles track\n",
      "# of episode :56, avg score : 1.0\n",
      "Track generation: 1049..1315 -> 266-tiles track\n",
      "# of episode :57, avg score : -0.1\n",
      "Track generation: 1345..1685 -> 340-tiles track\n",
      "# of episode :58, avg score : -0.1\n",
      "Track generation: 929..1167 -> 238-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1059..1328 -> 269-tiles track\n",
      "# of episode :59, avg score : -0.1\n",
      "Track generation: 981..1236 -> 255-tiles track\n",
      "# of episode :60, avg score : 1.0\n",
      "Track generation: 1220..1529 -> 309-tiles track\n",
      "# of episode :61, avg score : -0.1\n",
      "Track generation: 1062..1332 -> 270-tiles track\n",
      "# of episode :62, avg score : -0.1\n",
      "Track generation: 1148..1439 -> 291-tiles track\n",
      "# of episode :63, avg score : -0.1\n",
      "Track generation: 983..1235 -> 252-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1106..1387 -> 281-tiles track\n",
      "# of episode :64, avg score : -0.1\n",
      "Track generation: 1068..1339 -> 271-tiles track\n",
      "# of episode :65, avg score : -0.1\n",
      "Track generation: 1285..1611 -> 326-tiles track\n",
      "# of episode :66, avg score : -0.1\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "# of episode :67, avg score : -0.1\n",
      "Track generation: 1095..1373 -> 278-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1209..1515 -> 306-tiles track\n",
      "# of episode :68, avg score : -0.1\n",
      "Track generation: 1167..1463 -> 296-tiles track\n",
      "# of episode :69, avg score : -0.1\n",
      "Track generation: 1215..1523 -> 308-tiles track\n",
      "# of episode :70, avg score : -0.1\n",
      "Track generation: 1292..1619 -> 327-tiles track\n",
      "# of episode :71, avg score : -0.1\n",
      "Track generation: 1099..1378 -> 279-tiles track\n",
      "# of episode :72, avg score : -0.1\n",
      "Track generation: 1179..1478 -> 299-tiles track\n",
      "# of episode :73, avg score : -0.1\n",
      "Track generation: 1107..1388 -> 281-tiles track\n",
      "# of episode :74, avg score : -0.1\n",
      "Track generation: 1209..1519 -> 310-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1233..1544 -> 311-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1234..1555 -> 321-tiles track\n",
      "# of episode :75, avg score : 1.0\n",
      "Track generation: 1232..1553 -> 321-tiles track\n",
      "# of episode :76, avg score : 1.0\n",
      "Track generation: 1214..1522 -> 308-tiles track\n",
      "# of episode :77, avg score : -0.1\n",
      "Track generation: 1151..1450 -> 299-tiles track\n",
      "# of episode :78, avg score : 1.0\n",
      "Track generation: 1213..1529 -> 316-tiles track\n",
      "# of episode :79, avg score : 1.0\n",
      "Track generation: 1252..1569 -> 317-tiles track\n",
      "# of episode :80, avg score : -0.1\n",
      "Track generation: 1040..1304 -> 264-tiles track\n",
      "# of episode :81, avg score : -0.1\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "# of episode :82, avg score : -0.1\n",
      "Track generation: 1121..1408 -> 287-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1048..1319 -> 271-tiles track\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of episode :83, avg score : 1.0\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "# of episode :84, avg score : -0.1\n",
      "Track generation: 1140..1429 -> 289-tiles track\n",
      "# of episode :85, avg score : -0.1\n",
      "Track generation: 1114..1400 -> 286-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1052..1319 -> 267-tiles track\n",
      "# of episode :86, avg score : -0.1\n",
      "Track generation: 1045..1313 -> 268-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1131..1418 -> 287-tiles track\n",
      "# of episode :87, avg score : -0.1\n",
      "Track generation: 1122..1412 -> 290-tiles track\n",
      "# of episode :88, avg score : 1.0\n",
      "Track generation: 1239..1553 -> 314-tiles track\n",
      "# of episode :89, avg score : -0.1\n",
      "Track generation: 1022..1283 -> 261-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1123..1408 -> 285-tiles track\n",
      "# of episode :90, avg score : -0.1\n",
      "Track generation: 1158..1462 -> 304-tiles track\n",
      "# of episode :91, avg score : 1.0\n",
      "Track generation: 1313..1645 -> 332-tiles track\n",
      "# of episode :92, avg score : -0.1\n",
      "Track generation: 1000..1254 -> 254-tiles track\n",
      "# of episode :93, avg score : 0.9\n",
      "Track generation: 1259..1578 -> 319-tiles track\n",
      "# of episode :94, avg score : -0.1\n",
      "Track generation: 1316..1655 -> 339-tiles track\n",
      "# of episode :95, avg score : 1.0\n",
      "Track generation: 1086..1367 -> 281-tiles track\n",
      "# of episode :96, avg score : 1.0\n",
      "Track generation: 988..1238 -> 250-tiles track\n",
      "# of episode :97, avg score : 0.9\n",
      "Track generation: 1072..1344 -> 272-tiles track\n",
      "# of episode :98, avg score : -0.1\n",
      "Track generation: 1152..1444 -> 292-tiles track\n",
      "# of episode :99, avg score : -0.1\n",
      "Track generation: 1066..1341 -> 275-tiles track\n",
      "# of episode :100, avg score : 1.0\n",
      "Track generation: 1070..1341 -> 271-tiles track\n",
      "# of episode :101, avg score : -0.1\n",
      "Track generation: 1231..1543 -> 312-tiles track\n",
      "# of episode :102, avg score : -0.1\n",
      "Track generation: 1168..1464 -> 296-tiles track\n",
      "# of episode :103, avg score : -0.1\n",
      "Track generation: 1020..1279 -> 259-tiles track\n",
      "# of episode :104, avg score : -0.1\n",
      "Track generation: 1080..1359 -> 279-tiles track\n",
      "# of episode :105, avg score : 1.0\n",
      "Track generation: 1275..1598 -> 323-tiles track\n",
      "# of episode :106, avg score : -0.1\n",
      "Track generation: 1099..1381 -> 282-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1063..1333 -> 270-tiles track\n",
      "# of episode :107, avg score : -0.1\n",
      "Track generation: 1123..1408 -> 285-tiles track\n",
      "# of episode :108, avg score : -0.1\n",
      "Track generation: 1228..1539 -> 311-tiles track\n",
      "# of episode :109, avg score : -0.1\n",
      "Track generation: 1151..1443 -> 292-tiles track\n",
      "# of episode :110, avg score : -0.1\n",
      "Track generation: 1171..1468 -> 297-tiles track\n",
      "# of episode :111, avg score : -0.1\n",
      "Track generation: 1212..1519 -> 307-tiles track\n",
      "# of episode :112, avg score : -0.1\n",
      "Track generation: 1270..1592 -> 322-tiles track\n",
      "# of episode :113, avg score : -0.1\n",
      "Track generation: 1248..1564 -> 316-tiles track\n",
      "# of episode :114, avg score : -0.1\n",
      "Track generation: 1096..1374 -> 278-tiles track\n",
      "# of episode :115, avg score : -0.1\n",
      "Track generation: 1119..1403 -> 284-tiles track\n",
      "# of episode :116, avg score : -0.1\n",
      "Track generation: 1154..1447 -> 293-tiles track\n",
      "# of episode :117, avg score : -0.1\n",
      "Track generation: 1171..1468 -> 297-tiles track\n",
      "# of episode :118, avg score : -0.1\n",
      "Track generation: 1139..1428 -> 289-tiles track\n",
      "# of episode :119, avg score : -0.1\n",
      "Track generation: 1061..1339 -> 278-tiles track\n",
      "# of episode :120, avg score : 1.0\n",
      "Track generation: 1006..1269 -> 263-tiles track\n",
      "# of episode :121, avg score : 1.0\n",
      "Track generation: 1161..1455 -> 294-tiles track\n",
      "# of episode :122, avg score : -0.1\n",
      "Track generation: 1156..1448 -> 292-tiles track\n",
      "# of episode :123, avg score : -0.1\n",
      "Track generation: 1207..1513 -> 306-tiles track\n",
      "# of episode :124, avg score : -0.1\n",
      "Track generation: 1114..1397 -> 283-tiles track\n",
      "# of episode :125, avg score : -0.1\n",
      "Track generation: 1114..1405 -> 291-tiles track\n",
      "# of episode :126, avg score : 1.0\n",
      "Track generation: 1332..1669 -> 337-tiles track\n",
      "# of episode :127, avg score : -0.1\n",
      "Track generation: 1019..1278 -> 259-tiles track\n",
      "# of episode :128, avg score : -0.1\n",
      "Track generation: 1102..1380 -> 278-tiles track\n",
      "# of episode :129, avg score : -0.1\n",
      "Track generation: 1065..1342 -> 277-tiles track\n",
      "# of episode :130, avg score : 1.0\n",
      "Track generation: 1123..1410 -> 287-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1204..1509 -> 305-tiles track\n",
      "# of episode :131, avg score : -0.1\n",
      "Track generation: 1199..1503 -> 304-tiles track\n",
      "# of episode :132, avg score : -0.1\n",
      "Track generation: 1059..1328 -> 269-tiles track\n",
      "# of episode :133, avg score : 0.9\n",
      "Track generation: 945..1191 -> 246-tiles track\n",
      "# of episode :134, avg score : 1.0\n",
      "Track generation: 1224..1534 -> 310-tiles track\n",
      "# of episode :135, avg score : -0.1\n",
      "Track generation: 1128..1414 -> 286-tiles track\n",
      "# of episode :136, avg score : -0.1\n",
      "Track generation: 1151..1443 -> 292-tiles track\n",
      "# of episode :137, avg score : -0.1\n",
      "Track generation: 1261..1581 -> 320-tiles track\n",
      "# of episode :138, avg score : -0.1\n",
      "Track generation: 1064..1333 -> 269-tiles track\n",
      "# of episode :139, avg score : -0.1\n",
      "Track generation: 1287..1613 -> 326-tiles track\n",
      "# of episode :140, avg score : -0.1\n",
      "Track generation: 1117..1400 -> 283-tiles track\n",
      "# of episode :141, avg score : -0.1\n",
      "Track generation: 1057..1325 -> 268-tiles track\n",
      "# of episode :142, avg score : -0.1\n",
      "Track generation: 1109..1396 -> 287-tiles track\n",
      "# of episode :143, avg score : 1.0\n",
      "Track generation: 944..1184 -> 240-tiles track\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3c93c3d4422d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mnext_rgb_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdie\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;31m# don't penalize \"die state\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdie\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mFPS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"state_pixels\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mstep_reward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglViewport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVP_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVP_H\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_road\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mgeom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py\u001b[0m in \u001b[0;36mrender_road\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolygons_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"v3f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolygons_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"c4f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# gl.GL_QUADS,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         )\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[0mvl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGL_QUADS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender_indicators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\pyglet\\graphics\\vertexdomain.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \"\"\"\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\pyglet\\graphics\\vertexdomain.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, mode, vertex_list)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mglPushClientAttrib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGL_CLIENT_VERTEX_ARRAY_BIT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_attributes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mattribute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\openai\\lib\\site-packages\\pyglet\\graphics\\vertexbuffer.py\u001b[0m in \u001b[0;36mbind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m                 \u001b[0mglBufferData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                 glBufferSubData(self.target, self._dirty_min, size,\n\u001b[0m\u001b[0;32m    399\u001b[0m                                 self.data_ptr + self._dirty_min)\n\u001b[0;32m    400\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dirty_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "#Hyperparameters\n",
    "lr_mu        = 0.0005\n",
    "lr_q         = 0.001\n",
    "gamma        = 0.99\n",
    "batch_size   = 32\n",
    "buffer_limit = 100000\n",
    "tau          = 0.005 # for target network soft update\n",
    "num_frames = 4\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "\n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "\n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append(a)\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask = 0.0 if done else 1.0 \n",
    "            done_mask_lst.append([done_mask])\n",
    "            \n",
    "        r_lst = torch.tensor(r_lst, dtype=torch.double, device=device)\n",
    "        a_lst = torch.tensor(a_lst, dtype=torch.double, device=device)\n",
    "        s_lst = torch.tensor(s_lst, dtype=torch.double, device=device)\n",
    "        s_prime_lst = torch.tensor(s_prime_lst, dtype=torch.double, device=device)\n",
    "        done_mask_lst = torch.tensor(done_mask_lst, dtype=torch.double, device=device)\n",
    "        \n",
    "        return s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "    \n",
    "    \n",
    "class MuNet(torch.nn.Module):\n",
    "    def __init__(self, num_frames= 4, action_dim=3):\n",
    "        super(MuNet, self).__init__()\n",
    "   \n",
    "        self.cnn_base = nn.Sequential(  # input shape (4, 96, 96)\n",
    "            nn.Conv2d(num_frames, 8, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2),  # (8, 47, 47)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # (16, 23, 23)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # (32, 11, 11)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1),  # (64, 5, 5)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1),  # (128, 3, 3)\n",
    "            nn.ReLU(),  # activation\n",
    "        )  # output shape (256, 1, 1)\n",
    "        self.steer = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1))\n",
    "        self.gas = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1),nn.Softplus())\n",
    "        self.break_ = nn.Sequential(nn.Linear(256, 100), nn.ReLU(), nn.Linear(100, 1),nn.Softplus())        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Forward pass\n",
    "        x = self.cnn_base(x)\n",
    "        x = x.view(-1, 256) \n",
    "        steer = self.steer(x)\n",
    "        gas = self.gas(x)\n",
    "        break_ = self.break_(x)\n",
    "        x=torch.cat([steer, gas, break_], dim=1)\n",
    "        x = torch.tanh(x)*1\n",
    "     \n",
    "        return x    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "class QNet(torch.nn.Module):\n",
    "    def __init__(self, num_frames= 4, action_dim=3):\n",
    "        super(QNet, self).__init__()\n",
    "       \n",
    "        self.cnn_base = nn.Sequential(  # input shape (4, 96, 96)\n",
    "            nn.Conv2d(num_frames, 8, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2),  # (8, 47, 47)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2),  # (16, 23, 23)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2),  # (32, 11, 11)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1),  # (64, 5, 5)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1),  # (128, 3, 3)\n",
    "            nn.ReLU(),  # activation\n",
    "        )  # output shape (256, 1, 1)\n",
    "        \n",
    "        self.v = nn.Sequential(nn.Linear(256+action_dim, 200), nn.ReLU(), nn.Linear(200, 1))\n",
    "    \n",
    "    def forward(self, x,a):\n",
    "        \n",
    "        # Forward pass\n",
    "        x = self.cnn_base(x)\n",
    "        x = x.view(-1, 256) \n",
    "        x = torch.cat([x,a], dim=1)\n",
    "        x = self.v(x)\n",
    "       \n",
    "        \n",
    "        return x    \n",
    "        \n",
    "    \n",
    "    \n",
    "      \n",
    "def train(mu, mu_target, q, q_target, memory, q_optimizer, mu_optimizer):\n",
    "    s,a,r,s_prime,done_mask  = memory.sample(batch_size)\n",
    "    \n",
    "    target = r + gamma * q_target(s_prime, mu_target(s_prime)) * done_mask\n",
    "    q_loss = F.smooth_l1_loss(q(s,a), target.detach())\n",
    "    q_optimizer.zero_grad()\n",
    "    q_loss.backward()\n",
    "    q_optimizer.step()\n",
    "    \n",
    "    mu_loss = -q(s,mu(s)).mean() # That's all for the policy loss.\n",
    "    mu_optimizer.zero_grad()\n",
    "    mu_loss.backward()\n",
    "    mu_optimizer.step()\n",
    "    \n",
    "def soft_update(net, net_target):\n",
    "    for param_target, param in zip(net_target.parameters(), net.parameters()):\n",
    "        param_target.data.copy_(param_target.data * (1.0 - tau) + param.data * tau)\n",
    "    \n",
    "    \n",
    "def rgb2gray(rgb, norm=True):\n",
    "    # rgb image -> gray [0, 1]\n",
    "    gray = np.dot(rgb[..., :], [0.299, 0.587, 0.114])\n",
    "    if norm:\n",
    "        # normalize\n",
    "        gray = gray / 128. - 1.\n",
    "    return gray    \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")      \n",
    "    \n",
    "env = gym.make('CarRacing-v0')\n",
    "#env = gym.wrappers.TimeLimit(env, max_episode_steps = 1000)\n",
    "env.seed(0)\n",
    "\n",
    "reward_history = deque(maxlen=100)\n",
    "for _ in range(100):\n",
    "    reward_history.append(0.0)\n",
    "    \n",
    "    \n",
    "    \n",
    "memory = ReplayBuffer()\n",
    "\n",
    "\n",
    "q, q_target = QNet().double().to(device), QNet().double().to(device)\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "mu, mu_target = MuNet().double().to(device), MuNet().double().to(device)\n",
    "mu_target.load_state_dict(mu.state_dict())\n",
    "\n",
    "mu_optimizer = optim.Adam(mu.parameters(), lr=lr_mu)\n",
    "q_optimizer  = optim.Adam(q.parameters(), lr=lr_q)\n",
    "\n",
    "\n",
    "print_interval = 20\n",
    "score = 0.0\n",
    "scores = []\n",
    "for n_epi in range(3000):\n",
    "    rgb_image = env.reset()\n",
    "    gray_image = rgb2gray(rgb_image)\n",
    "    stack = [gray_image] * num_frames\n",
    "    state = stack\n",
    "    s = np.array(stack)\n",
    "    s = torch.from_numpy(s).double().to(device).unsqueeze(0)\n",
    "    die = False\n",
    "        \n",
    "    while True:\n",
    "        env.render()\n",
    "        \n",
    "        a = mu(s)[0]\n",
    "        a = a.cpu().detach().numpy() + 0.2*np.random.normal(3)\n",
    "        action = a\n",
    "\n",
    "        next_rgb_image, r, die, _ = env.step(a)\n",
    "        # don't penalize \"die state\"\n",
    "        if die:\n",
    "            r =r + 100 - 0.05\n",
    "        # green penalty\n",
    "        if np.mean(rgb_image[:, :, 1]) > 185.0:\n",
    "            r =r - 0.05\n",
    "\n",
    "        reward_history.append(r)\n",
    "        avg_rewards = sum(reward_history) / len(reward_history)\n",
    "        # if no reward recently, end the episode\n",
    "        done = True if avg_rewards <= -0.1 else False\n",
    "        \n",
    "        score = score + r\n",
    "        if die or done:\n",
    "            scores.append(score)\n",
    "            score = 0.0\n",
    "\n",
    "            break        \n",
    "        \n",
    "        next_gray_image = rgb2gray(next_rgb_image)\n",
    "        stack.pop(0)\n",
    "        stack.append(next_gray_image)\n",
    "        next_state = stack\n",
    "        next_s = np.array(stack)\n",
    "        next_s = torch.from_numpy(next_s).double().to(device).unsqueeze(0)\n",
    "        memory.put((state,action,r,next_state,done))\n",
    "        \n",
    "        s = next_s\n",
    "        state = next_state\n",
    "        rgb_image = next_rgb_image\n",
    "                \n",
    "    if memory.size()>2000:\n",
    "        for i in range(10):\n",
    "            train(mu, mu_target, q, q_target, memory, q_optimizer, mu_optimizer)\n",
    "            soft_update(mu, mu_target)\n",
    "            soft_update(q,  q_target)\n",
    "        \n",
    "    #clear_output(wait=True)\n",
    "    print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, avg_rewards))\n",
    "\n",
    "env.close()\n",
    "\n",
    "print(sum(scores))\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(\"./param\"):\n",
    "    os.makedirs(\"./param\")\n",
    "torch.save(mu.state_dict(), 'param/DDPG_net_params.pkl')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "plt.plot(range(len(scores)), np.array(scores), 'b', linewidth = 2, label = 'DDGP')\n",
    "plt.legend(prop={'size':12})\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total rewards')\n",
    "#plt.xlim(0, no_of_episodes)\n",
    "#plt.ylim(0, 20000)\n",
    "#plt.legend(['Double DQN', 'Dueling DQN', 'D3QN'], loc=4)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "from time import sleep\n",
    "\n",
    "for n_epi in range(2):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "        \n",
    "    while not done:\n",
    "        a = mu(torch.from_numpy(s).float()) \n",
    "        a = a.item() + ou_noise()[0]\n",
    "        s_prime, r, done, info = env.step([a])\n",
    "        env.render()\n",
    "        sleep(0.01)\n",
    "        score +=r\n",
    "        s = s_prime\n",
    "                \n",
    "        \n",
    "    if n_epi%print_interval==0 and n_epi!=0:\n",
    "        print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, score/print_interval))\n",
    "        score = 0.0\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
